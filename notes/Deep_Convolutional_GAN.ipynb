{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wko1014/GAN_Study/blob/main/notes/Deep_Convolutional_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lFdK6FtFdgA-"
      },
      "cell_type": "code",
      "source": [
        "# Import APIs\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zk6z15JDdk6j",
        "outputId": "7ee1bb22-54a3-49fe-e3c2-1513bb6a72d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# Download MNIST Dataset\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./MNIST_data/data/\", one_hot=True)\n",
        "\n",
        "# Define Hyperparameters and Placehoders\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "learning_rate = 1e-3\n",
        "n_noise = 100\n",
        "n_image = 28 * 28\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
        "is_training = tf.placeholder(tf.bool)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_data/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST_data/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST_data/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST_data/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rg6O8nzjAz9g"
      },
      "cell_type": "code",
      "source": [
        "# Define Moduels\n",
        "def leaky_relu(x, leak=0.2):\n",
        "    return tf.maximum(x, x * leak)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZ7ylDiZdk86"
      },
      "cell_type": "code",
      "source": [
        "# Define Generator (George)\n",
        "def generator(noise):\n",
        "    with tf.variable_scope(\"george\"):\n",
        "        layer1 = tf.layers.dense(noise, 128*7*7)\n",
        "        layer1 = tf.reshape(layer1, [-1, 7, 7, 128])\n",
        "        layer1 = tf.nn.relu(tf.layers.batch_normalization(layer1, training=is_training))\n",
        "\n",
        "        layer2 = tf.layers.conv2d_transpose(layer1, 64, [5, 5], strides=(2, 2), padding=\"SAME\")\n",
        "        layer2 = tf.nn.relu(tf.layers.batch_normalization(layer2, training=is_training))\n",
        "\n",
        "        layer3 = tf.layers.conv2d_transpose(layer2, 32, [5, 5], strides=(2, 2), padding=\"SAME\")\n",
        "        layer3 = tf.nn.relu(tf.layers.batch_normalization(layer3, training=is_training))\n",
        "\n",
        "        output = tf.layers.conv2d_transpose(layer3, 1, [5, 5], strides=(1, 1), padding=\"SAME\")\n",
        "        output = tf.nn.tanh(output)\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ac4pn2Tidk_O"
      },
      "cell_type": "code",
      "source": [
        "# Define Discriminator (Danielle)\n",
        "def discriminator(image, reuse=False):\n",
        "    with tf.variable_scope(\"danielle\", reuse=reuse):\n",
        "        layer1 = tf.layers.conv2d(image, 32, [5, 5], strides=(2, 2), padding=\"SAME\")\n",
        "        layer1 = leaky_relu(layer1)\n",
        "\n",
        "        layer2 = tf.layers.conv2d(layer1, 64, [5, 5], strides=(2, 2), padding=\"SAME\")\n",
        "        layer2 = leaky_relu(tf.layers.batch_normalization(layer2, training=is_training))\n",
        "\n",
        "        layer3 = tf.layers.conv2d(layer2, 128, [5, 5], strides=(2, 2), padding=\"SAME\")\n",
        "        layer3 = leaky_relu(tf.layers.batch_normalization(layer3, training=is_training))\n",
        "\n",
        "        output = tf.contrib.layers.flatten(layer3)\n",
        "        output = tf.layers.dense(output, 1, activation=None)\n",
        "        output = tf.nn.sigmoid(output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9tGgazPdlBT",
        "outputId": "866f1b7f-a91c-41de-fc8a-16535036487c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "# Sample Random Noise Vector\n",
        "def get_noise(batch_size, n_noise):\n",
        "  return np.random.uniform(-1., 1., size=(batch_size, n_noise))\n",
        "\n",
        "def get_moving_noise(batch_size, n_noise):\n",
        "    assert batch_size > 0\n",
        "    noise_list = []\n",
        "    base_noise = np.random.uniform(-1., 1., size=[n_noise])\n",
        "    end_noise = np.random.uniform(-1., 1., size=[n_noise])\n",
        "\n",
        "    step = (end_noise - base_noise) / batch_size\n",
        "    noise = np.copy(base_noise)\n",
        "    for _ in range(batch_size - 1):\n",
        "        noise_list.append(noise)\n",
        "        noise = noise + step\n",
        "    noise_list.append(end_noise)\n",
        "\n",
        "    return noise_list\n",
        "\n",
        "# George Generates Counterfeits\n",
        "counterfeits = generator(noise=Z)\n",
        "\n",
        "# Danielle Discriminates Real Bills and Counterfeits\n",
        "D_real = discriminator(X)\n",
        "D_counterfeits = discriminator(counterfeits, reuse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-c9092b1ed638>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-5-c9092b1ed638>:5: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.batch_normalization instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-c9092b1ed638>:7: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d_transpose instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-889fc310b2eb>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NMUdTN_jdlDp"
      },
      "cell_type": "code",
      "source": [
        "# GANs Objective Function\n",
        "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_counterfeits))\n",
        "loss_G = tf.reduce_mean(tf.log(D_counterfeits))\n",
        "\n",
        "# Collect George's and Danielle's Variables\n",
        "D_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"danielle\")\n",
        "G_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"george\")\n",
        "\n",
        "# Optimization using Adam Optimizer\n",
        "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list=D_var_list)\n",
        "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list=G_var_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BrOyehmrUC7F"
      },
      "cell_type": "code",
      "source": [
        "# Nerual Networks Training\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "loss_var_D, loss_var_G = 0, 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(total_batch):\n",
        "        batch_x, _ = mnist.train.next_batch(batch_size)\n",
        "        batch_x = np.reshape(batch_x, newshape=[-1, 28, 28, 1])\n",
        "        noise = get_noise(batch_size, n_noise)\n",
        "\n",
        "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X: batch_x, Z: noise, is_training:True})\n",
        "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict={Z: noise, is_training:True})\n",
        "\n",
        "    print(\"Epoch:\", \"%04d\" % epoch, \"D loss: {:.4}\".format(loss_val_D), \"G loss: {:.4}\".format(loss_val_G))\n",
        "\n",
        "\n",
        "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
        "        sample_size = 10\n",
        "        noise = get_noise(sample_size, n_noise)\n",
        "        generated_samples = sess.run(counterfeits, feed_dict={Z: noise, is_training:False})\n",
        "        moving_noise = get_moving_noise(sample_size, n_noise)\n",
        "        moving_samples = sess.run(counterfeits, feed_dict={Z: moving_noise, is_training:False})\n",
        "\n",
        "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
        "\n",
        "        for i in range(sample_size):\n",
        "            ax[0][i].set_axis_off()\n",
        "            ax[1][i].set_axis_off()\n",
        "            ax[0][i].imshow(np.reshape(generated_samples[i], (28, 28)))\n",
        "            ax[1][i].imshow(np.reshape(moving_samples[i], (28, 28)))\n",
        "\n",
        "        plt.savefig(\"./{}.png\".format(str(epoch).zfill(3)), bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "\n",
        "print(\"Optimization Complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHqvz1RSdlM0"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "img = mpimg.imread(\"./099.png\")\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}