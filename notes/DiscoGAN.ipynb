{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "discogan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wko1014/GAN_Study/blob/main/notes/DiscoGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VTJUCf3Oor-J"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "import scipy.ndimage.interpolation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tBVLi5_yovYh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "503f5183-f027-42c4-c9b5-5088f0cb937b"
      },
      "cell_type": "code",
      "source": [
        "mb_size = 32\n",
        "X_dim = 784\n",
        "z_dim = 64\n",
        "h_dim = 128\n",
        "lr = 1e-3\n",
        "d_steps = 3\n",
        "\n",
        "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-69cded1763fd>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YfU24ShNoxRr"
      },
      "cell_type": "code",
      "source": [
        "def plot(samples):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(4, 4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
        "\n",
        "\n",
        "def log(x):\n",
        "    return tf.log(x + 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9r-Hh9Co0gK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e46ab373-8134-428d-89c5-27de17acfd09"
      },
      "cell_type": "code",
      "source": [
        "X_A = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
        "X_B = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
        "\n",
        "D_A_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
        "D_A_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
        "D_A_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
        "D_A_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
        "\n",
        "D_B_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
        "D_B_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
        "D_B_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
        "D_B_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
        "\n",
        "G_AB_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
        "G_AB_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
        "G_AB_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
        "G_AB_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
        "\n",
        "G_BA_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
        "G_BA_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
        "G_BA_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
        "G_BA_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
        "\n",
        "theta_D = [D_A_W1, D_A_W2, D_A_b1, D_A_b2,\n",
        "           D_B_W1, D_B_W2, D_B_b1, D_B_b2]\n",
        "theta_G = [G_AB_W1, G_AB_W2, G_AB_b1, G_AB_b2,\n",
        "           G_BA_W1, G_BA_W2, G_BA_b1, G_BA_b2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rh9TcLFGo2iP"
      },
      "cell_type": "code",
      "source": [
        "def D_A(X):\n",
        "    h = tf.nn.relu(tf.matmul(X, D_A_W1) + D_A_b1)\n",
        "    return tf.nn.sigmoid(tf.matmul(h, D_A_W2) + D_A_b2)\n",
        "\n",
        "\n",
        "def D_B(X):\n",
        "    h = tf.nn.relu(tf.matmul(X, D_B_W1) + D_B_b1)\n",
        "    return tf.nn.sigmoid(tf.matmul(h, D_B_W2) + D_B_b2)\n",
        "\n",
        "\n",
        "def G_AB(X):\n",
        "    h = tf.nn.relu(tf.matmul(X, G_AB_W1) + G_AB_b1)\n",
        "    return tf.nn.sigmoid(tf.matmul(h, G_AB_W2) + G_AB_b2)\n",
        "\n",
        "\n",
        "def G_BA(X):\n",
        "    h = tf.nn.relu(tf.matmul(X, G_BA_W1) + G_BA_b1)\n",
        "    return tf.nn.sigmoid(tf.matmul(h, G_BA_W2) + G_BA_b2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2oI8hjGjo4dw"
      },
      "cell_type": "code",
      "source": [
        "# Discriminator A\n",
        "X_BA = G_BA(X_B)\n",
        "D_A_real = D_A(X_A)\n",
        "D_A_fake = D_A(X_BA)\n",
        "\n",
        "# Discriminator B\n",
        "X_AB = G_AB(X_A)\n",
        "D_B_real = D_B(X_B)\n",
        "D_B_fake = D_B(X_AB)\n",
        "\n",
        "# Generator AB\n",
        "X_ABA = G_BA(X_AB)\n",
        "\n",
        "# Generator BA\n",
        "X_BAB = G_AB(X_BA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GzSaqrw8o8rS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "94aa8cd0-eceb-4175-801c-55a2c1178307"
      },
      "cell_type": "code",
      "source": [
        "# Discriminator loss\n",
        "L_D_A = -tf.reduce_mean(log(D_A_real) + log(1 - D_A_fake))\n",
        "L_D_B = -tf.reduce_mean(log(D_B_real) + log(1 - D_B_fake))\n",
        "\n",
        "D_loss = L_D_A + L_D_B\n",
        "\n",
        "# Generator loss\n",
        "L_adv_B = -tf.reduce_mean(log(D_B_fake))\n",
        "L_recon_A = tf.reduce_mean(tf.reduce_sum((X_A - X_ABA)**2, 1))\n",
        "L_G_AB = L_adv_B + L_recon_A\n",
        "\n",
        "L_adv_A = -tf.reduce_mean(log(D_A_fake))\n",
        "L_recon_B = tf.reduce_mean(tf.reduce_sum((X_B - X_BAB)**2, 1))\n",
        "L_G_BA = L_adv_A + L_recon_B\n",
        "\n",
        "G_loss = L_G_AB + L_G_BA\n",
        "\n",
        "# Solvers\n",
        "solver = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "D_solver = solver.minimize(D_loss, var_list=theta_D)\n",
        "G_solver = solver.minimize(G_loss, var_list=theta_G)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nh5SmQKro-xH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5cc122f0-370b-4a5a-a666-0bfc826edc75"
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "# Gather training data from 2 domains\n",
        "X_train = mnist.train.images\n",
        "half = int(X_train.shape[0] / 2)\n",
        "# Real image\n",
        "X_train1 = X_train[:half]\n",
        "# Rotated image\n",
        "X_train2 = X_train[half:].reshape(-1, 28, 28)\n",
        "X_train2 = scipy.ndimage.interpolation.rotate(X_train2, 90, axes=(1, 2))\n",
        "X_train2 = X_train2.reshape(-1, 28*28)\n",
        "# Cleanup\n",
        "del X_train\n",
        "\n",
        "\n",
        "def sample_X(X, size):\n",
        "    start_idx = np.random.randint(0, X.shape[0]-size)\n",
        "    return X[start_idx:start_idx+size]\n",
        "\n",
        "\n",
        "if not os.path.exists('out/'):\n",
        "    os.makedirs('out/')\n",
        "\n",
        "i = 0\n",
        "\n",
        "for it in range(10000):\n",
        "    # Sample data from both domains\n",
        "    X_A_mb = sample_X(X_train1, mb_size)\n",
        "    X_B_mb = sample_X(X_train2, mb_size)\n",
        "\n",
        "    _, D_loss_curr = sess.run(\n",
        "        [D_solver, D_loss], feed_dict={X_A: X_A_mb, X_B: X_B_mb}\n",
        "    )\n",
        "\n",
        "    _, G_loss_curr = sess.run(\n",
        "        [G_solver, G_loss], feed_dict={X_A: X_A_mb, X_B: X_B_mb}\n",
        "    )\n",
        "\n",
        "    if it % 1000 == 0:\n",
        "        print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'\n",
        "              .format(it, D_loss_curr, G_loss_curr))\n",
        "\n",
        "        input_A = sample_X(X_train1, size=4)\n",
        "        input_B = sample_X(X_train2, size=4)\n",
        "\n",
        "        samples_A = sess.run(X_BA, feed_dict={X_B: input_B})\n",
        "        samples_B = sess.run(X_AB, feed_dict={X_A: input_A})\n",
        "\n",
        "        # The resulting image sample would be in 4 rows:\n",
        "        # row 1: real data from domain A, row 2 is its domain B translation\n",
        "        # row 3: real data from domain B, row 4 is its domain A translation\n",
        "        samples = np.vstack([input_A, samples_B, input_B, samples_A])\n",
        "\n",
        "        fig = plot(samples)\n",
        "        plt.savefig('out/{}.png'\n",
        "                    .format(str(i).zfill(3)), bbox_inches='tight')\n",
        "        i += 1\n",
        "        plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter: 0; D_loss: 2.767; G_loss: 432.3\n",
            "Iter: 1000; D_loss: 1.257; G_loss: 35.89\n",
            "Iter: 2000; D_loss: 0.8354; G_loss: 32.19\n",
            "Iter: 3000; D_loss: 1.18; G_loss: 26.58\n",
            "Iter: 4000; D_loss: 0.646; G_loss: 23.97\n",
            "Iter: 5000; D_loss: 0.3167; G_loss: 22.55\n",
            "Iter: 6000; D_loss: 0.541; G_loss: 25.96\n",
            "Iter: 7000; D_loss: 0.582; G_loss: 24.65\n",
            "Iter: 8000; D_loss: 0.5688; G_loss: 22.78\n",
            "Iter: 9000; D_loss: 0.4212; G_loss: 23.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M3-1EvC5veyP"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}